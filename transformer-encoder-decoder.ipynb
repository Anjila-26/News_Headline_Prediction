{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd00a200",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:40.122016Z",
     "iopub.status.busy": "2025-06-27T13:22:40.121792Z",
     "iopub.status.idle": "2025-06-27T13:22:41.491209Z",
     "shell.execute_reply": "2025-06-27T13:22:41.490415Z"
    },
    "papermill": {
     "duration": 1.379216,
     "end_time": "2025-06-27T13:22:41.492736",
     "exception": false,
     "start_time": "2025-06-27T13:22:40.113520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37303384",
   "metadata": {
    "papermill": {
     "duration": 0.00653,
     "end_time": "2025-06-27T13:22:41.506275",
     "exception": false,
     "start_time": "2025-06-27T13:22:41.499745",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bdbb563",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:41.519659Z",
     "iopub.status.busy": "2025-06-27T13:22:41.519331Z",
     "iopub.status.idle": "2025-06-27T13:22:43.296468Z",
     "shell.execute_reply": "2025-06-27T13:22:43.295747Z"
    },
    "papermill": {
     "duration": 1.785125,
     "end_time": "2025-06-27T13:22:43.297748",
     "exception": false,
     "start_time": "2025-06-27T13:22:41.512623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffpost.com/entry/covid-boosters-...</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "      <td>Carla K. Johnson, AP</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffpost.com/entry/american-airlin...</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "      <td>Mary Papenfuss</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-tweets...</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "      <td>Elyse Wanshel</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-parent...</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "      <td>Caroline Bologna</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffpost.com/entry/amy-cooper-lose...</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "      <td>Nina Golgowski</td>\n",
       "      <td>2022-09-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://www.huffpost.com/entry/covid-boosters-...   \n",
       "1  https://www.huffpost.com/entry/american-airlin...   \n",
       "2  https://www.huffpost.com/entry/funniest-tweets...   \n",
       "3  https://www.huffpost.com/entry/funniest-parent...   \n",
       "4  https://www.huffpost.com/entry/amy-cooper-lose...   \n",
       "\n",
       "                                            headline   category  \\\n",
       "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS   \n",
       "1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS   \n",
       "2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY   \n",
       "3  The Funniest Tweets From Parents This Week (Se...  PARENTING   \n",
       "4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS   \n",
       "\n",
       "                                   short_description               authors  \\\n",
       "0  Health experts said it is too early to predict...  Carla K. Johnson, AP   \n",
       "1  He was subdued by passengers and crew when he ...        Mary Papenfuss   \n",
       "2  \"Until you have a dog you don't understand wha...         Elyse Wanshel   \n",
       "3  \"Accidentally put grown-up toothpaste on my to...      Caroline Bologna   \n",
       "4  Amy Cooper accused investment firm Franklin Te...        Nina Golgowski   \n",
       "\n",
       "         date  \n",
       "0  2022-09-23  \n",
       "1  2022-09-23  \n",
       "2  2022-09-23  \n",
       "3  2022-09-23  \n",
       "4  2022-09-22  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read the file\n",
    "with open('/kaggle/input/news-category-dataset/News_Category_Dataset_v3.json') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "#Convert that into Dataframe or easier inspection\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# View the first item\n",
    "df = df.head(50000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb7e02c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:43.312163Z",
     "iopub.status.busy": "2025-06-27T13:22:43.311941Z",
     "iopub.status.idle": "2025-06-27T13:22:43.316077Z",
     "shell.execute_reply": "2025-06-27T13:22:43.315411Z"
    },
    "papermill": {
     "duration": 0.012236,
     "end_time": "2025-06-27T13:22:43.317102",
     "exception": false,
     "start_time": "2025-06-27T13:22:43.304866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total Number of data\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fec3fbb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:43.331308Z",
     "iopub.status.busy": "2025-06-27T13:22:43.331115Z",
     "iopub.status.idle": "2025-06-27T13:22:43.346480Z",
     "shell.execute_reply": "2025-06-27T13:22:43.345929Z"
    },
    "papermill": {
     "duration": 0.024011,
     "end_time": "2025-06-27T13:22:43.347705",
     "exception": false,
     "start_time": "2025-06-27T13:22:43.323694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__HEADLINE__\n",
      "Over 4 Million Americans Roll Up Sleeves For Omicron-Targeted COVID Boosters\n",
      "__SHORT DESCRIPTION__\n",
      "Health experts said it is too early to predict whether demand would match up with the 171 million doses of the new boosters the U.S. ordered for the fall.\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "__HEADLINE__\n",
      "World Cup Captains Want To Wear Rainbow Armbands In Qatar\n",
      "__SHORT DESCRIPTION__\n",
      "FIFA has come under pressure from several European soccer federations who want to support a human rights campaign against discrimination at the World Cup.\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "__HEADLINE__\n",
      "Golden Globes Returning To NBC In January After Year Off-Air\n",
      "__SHORT DESCRIPTION__\n",
      "For the past 18 months, Hollywood has effectively boycotted the Globes after reports that the HFPA’s 87 members of non-American journalists included no Black members.\n"
     ]
    }
   ],
   "source": [
    "#Take only headline and short_description\n",
    "df = df[['headline', 'short_description']]\n",
    "\n",
    "print(\"__HEADLINE__\")\n",
    "print(df['headline'][0])\n",
    "print(\"__SHORT DESCRIPTION__\")\n",
    "print(df['short_description'][0])\n",
    "print('-' * 110)\n",
    "print(\"__HEADLINE__\")\n",
    "print(df['headline'][10])\n",
    "print(\"__SHORT DESCRIPTION__\")\n",
    "print(df['short_description'][10])\n",
    "print('-' * 110)\n",
    "print(\"__HEADLINE__\")\n",
    "print(df['headline'][20])\n",
    "print(\"__SHORT DESCRIPTION__\")\n",
    "print(df['short_description'][20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad15437",
   "metadata": {
    "papermill": {
     "duration": 0.006327,
     "end_time": "2025-06-27T13:22:43.360553",
     "exception": false,
     "start_time": "2025-06-27T13:22:43.354226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Cleaning the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5849b493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:43.374402Z",
     "iopub.status.busy": "2025-06-27T13:22:43.374191Z",
     "iopub.status.idle": "2025-06-27T13:22:44.248889Z",
     "shell.execute_reply": "2025-06-27T13:22:44.248047Z"
    },
    "papermill": {
     "duration": 0.883567,
     "end_time": "2025-06-27T13:22:44.250484",
     "exception": false,
     "start_time": "2025-06-27T13:22:43.366917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__HEADLINE__\n",
      "over 4 million americans roll up sleeves for omicrontargeted covid boosters\n",
      "__SHORT DESCRIPTION__\n",
      "health experts said it is too early to predict whether demand would match up with the 171 million doses of the new boosters the us ordered for the fall\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "__HEADLINE__\n",
      "world cup captains want to wear rainbow armbands in qatar\n",
      "__SHORT DESCRIPTION__\n",
      "fifa has come under pressure from several european soccer federations who want to support a human rights campaign against discrimination at the world cup\n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "__HEADLINE__\n",
      "golden globes returning to nbc in january after year offair\n",
      "__SHORT DESCRIPTION__\n",
      "for the past 18 months hollywood has effectively boycotted the globes after reports that the hfpas 87 members of nonamerican journalists included no black members\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Remove punctuation and special characters (except words and spaces)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "df['headline'] = df['headline'].apply(clean_text)\n",
    "df['short_description'] = df['short_description'].apply(clean_text)\n",
    "\n",
    "print(\"__HEADLINE__\")\n",
    "print(df['headline'][0])\n",
    "print(\"__SHORT DESCRIPTION__\")\n",
    "print(df['short_description'][0])\n",
    "print('-' * 110)\n",
    "print(\"__HEADLINE__\")\n",
    "print(df['headline'][10])\n",
    "print(\"__SHORT DESCRIPTION__\")\n",
    "print(df['short_description'][10])\n",
    "print('-' * 110)\n",
    "print(\"__HEADLINE__\")\n",
    "print(df['headline'][20])\n",
    "print(\"__SHORT DESCRIPTION__\")\n",
    "print(df['short_description'][20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c5086d",
   "metadata": {
    "papermill": {
     "duration": 0.006417,
     "end_time": "2025-06-27T13:22:44.263828",
     "exception": false,
     "start_time": "2025-06-27T13:22:44.257411",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Build the Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "117dc13d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:44.277535Z",
     "iopub.status.busy": "2025-06-27T13:22:44.277318Z",
     "iopub.status.idle": "2025-06-27T13:22:46.136075Z",
     "shell.execute_reply": "2025-06-27T13:22:46.135295Z"
    },
    "papermill": {
     "duration": 1.867076,
     "end_time": "2025-06-27T13:22:46.137359",
     "exception": false,
     "start_time": "2025-06-27T13:22:44.270283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text.lower())\n",
    "\n",
    "def build_vocab(texts, min_freq=1):\n",
    "    \"\"\"\n",
    "    Builds vocabulary with proper special tokens.\n",
    "    \"\"\"\n",
    "    all_tokens = []\n",
    "    for text in texts:\n",
    "        tokens = tokenize(text)\n",
    "        all_tokens.extend(tokens)\n",
    "    \n",
    "    # Count word frequencies\n",
    "    word_freq = Counter(all_tokens)\n",
    "    \n",
    "    # Filter words by min frequency\n",
    "    filtered_words = [word for word, freq in word_freq.items() if freq >= min_freq]\n",
    "    \n",
    "    # Build vocab with special tokens\n",
    "    word2idx = {'<PAD>': 0, '<UNK>': 1, '<BOS>': 2, '<EOS>': 3}\n",
    "    \n",
    "    for idx, word in enumerate(filtered_words):\n",
    "        word2idx[word] = idx + 4  # Start after special tokens\n",
    "    \n",
    "    # Reverse mapping\n",
    "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "    \n",
    "    return word2idx, idx2word, word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9de65733",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:46.152033Z",
     "iopub.status.busy": "2025-06-27T13:22:46.151718Z",
     "iopub.status.idle": "2025-06-27T13:22:52.844483Z",
     "shell.execute_reply": "2025-06-27T13:22:52.843669Z"
    },
    "papermill": {
     "duration": 6.701426,
     "end_time": "2025-06-27T13:22:52.845797",
     "exception": false,
     "start_time": "2025-06-27T13:22:46.144371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 49302\n",
      "Top 10 words: [('the', 59090), ('to', 33483), ('a', 26303), ('of', 24966), ('in', 20948), ('and', 18685), ('for', 14349), ('is', 13008), ('on', 11245), ('trump', 9621)]\n"
     ]
    }
   ],
   "source": [
    "texts = df['headline'].tolist() + df['short_description'].tolist()\n",
    "word2idx, idx2word, word_freq = build_vocab(texts, min_freq=1)\n",
    "\n",
    "print(\"Vocab size:\", len(word2idx))\n",
    "print(\"Top 10 words:\", word_freq.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40d35b0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:52.860374Z",
     "iopub.status.busy": "2025-06-27T13:22:52.860135Z",
     "iopub.status.idle": "2025-06-27T13:22:52.871641Z",
     "shell.execute_reply": "2025-06-27T13:22:52.870917Z"
    },
    "papermill": {
     "duration": 0.020044,
     "end_time": "2025-06-27T13:22:52.872813",
     "exception": false,
     "start_time": "2025-06-27T13:22:52.852769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headline             0\n",
       "short_description    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if there is a null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a264ba13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:52.887247Z",
     "iopub.status.busy": "2025-06-27T13:22:52.887044Z",
     "iopub.status.idle": "2025-06-27T13:22:52.892160Z",
     "shell.execute_reply": "2025-06-27T13:22:52.891451Z"
    },
    "papermill": {
     "duration": 0.013333,
     "end_time": "2025-06-27T13:22:52.893189",
     "exception": false,
     "start_time": "2025-06-27T13:22:52.879856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Modified encode_text to use BOS/EOS tokens\n",
    "def encode_text(text, word2idx, max_len=32, add_special_tokens=True):\n",
    "    \"\"\"\n",
    "    Encode text with optional BOS/EOS tokens\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    if add_special_tokens:\n",
    "        ids = [word2idx['<BOS>']]  # Start with BOS\n",
    "        ids.extend([word2idx.get(token, word2idx['<UNK>']) for token in tokens])\n",
    "        ids.append(word2idx['<EOS>'])  # End with EOS\n",
    "    else:\n",
    "        ids = [word2idx.get(token, word2idx['<UNK>']) for token in tokens]\n",
    "    \n",
    "    # Truncate if too long, else pad\n",
    "    if len(ids) > max_len:\n",
    "        ids = ids[:max_len]\n",
    "    else:\n",
    "        ids += [word2idx['<PAD>']] * (max_len - len(ids))\n",
    "    \n",
    "    return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615efd84",
   "metadata": {
    "papermill": {
     "duration": 0.006554,
     "end_time": "2025-06-27T13:22:52.906724",
     "exception": false,
     "start_time": "2025-06-27T13:22:52.900170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Make the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8ac843a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:52.921036Z",
     "iopub.status.busy": "2025-06-27T13:22:52.920761Z",
     "iopub.status.idle": "2025-06-27T13:22:57.154627Z",
     "shell.execute_reply": "2025-06-27T13:22:57.153762Z"
    },
    "papermill": {
     "duration": 4.242927,
     "end_time": "2025-06-27T13:22:57.156262",
     "exception": false,
     "start_time": "2025-06-27T13:22:52.913335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, headline, short_description, word2idx, max_len=32):\n",
    "        \"\"\"\n",
    "        articles: list of article texts\n",
    "        highlights: list of summary texts\n",
    "        word2idx: vocabulary dictionary\n",
    "        max_len: max length for padding/truncation\n",
    "        \"\"\"\n",
    "        self.headline = headline\n",
    "        self.short_description = short_description\n",
    "        self.word2idx = word2idx\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.headline)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the raw article and summary\n",
    "        headline = self.headline[idx]\n",
    "        short_description = self.short_description[idx]\n",
    "\n",
    "        # Encode both\n",
    "        input_ids = encode_text(short_description, self.word2idx, self.max_len)\n",
    "        target_ids = encode_text(headline, self.word2idx, self.max_len)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(input_ids, dtype=torch.long),\n",
    "            \"target_ids\": torch.tensor(target_ids, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e1c1228",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:57.171741Z",
     "iopub.status.busy": "2025-06-27T13:22:57.171320Z",
     "iopub.status.idle": "2025-06-27T13:22:57.234792Z",
     "shell.execute_reply": "2025-06-27T13:22:57.233756Z"
    },
    "papermill": {
     "duration": 0.072578,
     "end_time": "2025-06-27T13:22:57.236195",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.163617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9d793b",
   "metadata": {
    "papermill": {
     "duration": 0.00758,
     "end_time": "2025-06-27T13:22:57.254540",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.246960",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Input Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eced00ac",
   "metadata": {
    "papermill": {
     "duration": 0.007282,
     "end_time": "2025-06-27T13:22:57.273919",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.266637",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's focus on the Encoder Part for now:\n",
    "\n",
    "### Transformer Encoder\n",
    "\n",
    "At first you can see that we have Input Embedding and the Positional Encoding so let's talk about that,\n",
    "\n",
    "**Embedding** -> So, we know that the first thing we do is tokenize and we recieve the set's of discrete tokens and embedding's job is to change the set of discrete tokens into the continous vector representation.\n",
    "\n",
    "Why the need to do this?\n",
    "Because, Transformer is the neural network and they understand the numbers and not the words, so we need to change them to the numerical representation forms such that they captures the semantic meaning and context.\n",
    "\n",
    "The transformer architecture starts with embedding sequences as vectors, and then encoding each token's position in the sequence so that tokens can be processed in parallel.\n",
    "\n",
    "Suppose, we have three tokens \n",
    "[\"Cat\", \"Dog\", \"Fish\"]\n",
    "\n",
    "We know that each token have their own unique ID in the modle vocab which the model recognize. If we embed them using the embedding layers we get the embedding vector.The length of this vector is also referred to as the number of dimensions, or dimensionality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ca2f0a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:57.358436Z",
     "iopub.status.busy": "2025-06-27T13:22:57.357577Z",
     "iopub.status.idle": "2025-06-27T13:22:57.364556Z",
     "shell.execute_reply": "2025-06-27T13:22:57.363821Z"
    },
    "papermill": {
     "duration": 0.020948,
     "end_time": "2025-06-27T13:22:57.366027",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.345079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class InputEmbeddings(nn.Module):\n",
    "    \"\"\"\n",
    "    Converts token indices into dense vector embeddings and scales them.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): Size of the vocabulary (number of unique tokens).\n",
    "        d_model (int): Dimensionality of the embedding vectors (also the model's hidden size).\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size: int, d_model: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model                  # Embedding dimension (same as model hidden size)\n",
    "        self.vocab_size = vocab_size            # Total number of tokens in vocabulary\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)  # Learnable embedding table\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): Tensor of token indices of shape (batch_size, seq_len)\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Embedded and scaled tensor of shape (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        # Multiply by sqrt(d_model) as recommended in the Transformer paper to help with convergence\n",
    "        return self.embedding(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca43cecc",
   "metadata": {
    "papermill": {
     "duration": 0.012024,
     "end_time": "2025-06-27T13:22:57.390773",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.378749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd950889",
   "metadata": {
    "papermill": {
     "duration": 0.011975,
     "end_time": "2025-06-27T13:22:57.415137",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.403162",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Positional Encoding** : It is added to give the model information about the position of each word in a sequence.\n",
    "\n",
    "Why the need of this? Because The word \"ate\" in \"The cat ate the fish\" is different from \"ate\" in \"Ate the cat the fish?\" — the order matters.\n",
    "\n",
    "The positional Encoding are generated using the special encoding equation, where the sin is use for the even embedding values and cos is used for odd emedding values\n",
    "\n",
    "The positional encoding for position `pos` and dimension `i` is defined as:\n",
    "\n",
    "$$\n",
    "\\text{PE}_{(pos, 2i)} = \\sin\\left(\\frac{pos}{10000^{\\frac{2i}{d}}}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{PE}_{(pos, 2i+1)} = \\cos\\left(\\frac{pos}{10000^{\\frac{2i}{d}}}\\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- \\( pos \\) is the position in the sequence,\n",
    "- \\( i \\) is the dimension index,\n",
    "- \\( d \\) is the total embedding dimension.\n",
    "\n",
    "Sin and Cosine are the periodic functions who have their values between -1 and 1.\n",
    "\n",
    "Why do we used them?\n",
    "\n",
    "**Provide the unique patterns for each position**\n",
    "1. The combination of sin and cos with different frequencies ensures that the each position has a unique encoding vector.\n",
    "2. No two positions have the same encoding, and nearby positions have similar vectors, which helps the model recognize local context.\n",
    "\n",
    "**Captures relative position information**\n",
    "1. The sinusoidal form makes it easy for the model to learn the relative positions between words.\n",
    "2. For example, PE(pos + k) can be expressed as a linear function of PE(pos), allowing the model to infer order differences like “word A is 2 steps ahead of word B”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8ed3d0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:57.440848Z",
     "iopub.status.busy": "2025-06-27T13:22:57.440541Z",
     "iopub.status.idle": "2025-06-27T13:22:57.446713Z",
     "shell.execute_reply": "2025-06-27T13:22:57.445935Z"
    },
    "papermill": {
     "duration": 0.020798,
     "end_time": "2025-06-27T13:22:57.447945",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.427147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements the sinusoidal positional encoding from the Transformer paper:\n",
    "    \"Attention is All You Need\" (Vaswani et al. 2017).\n",
    "\n",
    "    This adds information about token positions to the input embeddings, \n",
    "    enabling the model to capture order without recurrence.\n",
    "\n",
    "    Args:\n",
    "        d_model (int): Dimensionality of the model/embedding.\n",
    "        max_seq_length (int): Maximum sequence length supported.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize a matrix of shape (max_seq_length, d_model)\n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "\n",
    "        # Position indices (0 to max_seq_length-1) shaped as (max_seq_length, 1)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "        # Compute the div_term (frequency) for the sinusoidal functions.\n",
    "        # Only half (every 2nd dim) because sin and cos alternate over even and odd dims\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        # Apply sine to even indices in the array; 2i\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "\n",
    "        # Apply cosine to odd indices in the array; 2i+1\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        # Register as a buffer (non-learnable), adds a batch dimension for broadcasting\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))  # shape: (1, max_seq_length, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Adds positional encoding to the input tensor.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input of shape (batch_size, seq_len, d_model)\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Positionally encoded input of the same shape\n",
    "        \"\"\"\n",
    "        # Add positional encoding to the input\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81420ed",
   "metadata": {
    "papermill": {
     "duration": 0.007562,
     "end_time": "2025-06-27T13:22:57.462631",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.455069",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Multihead Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df9d6a0",
   "metadata": {
    "papermill": {
     "duration": 0.006747,
     "end_time": "2025-06-27T13:22:57.476264",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.469517",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Before that, What is self Attention?\n",
    "\n",
    "Self Attention is what enables the transformers to identify the relationship between tokens and to determine and focus on the most relevant ones. It allows a model to look at other positions in the same input sequence when encoding a word — hence the name \"self\" attention.\n",
    "\n",
    "Self-attention determines:\n",
    "“Which other words in the sentence should I pay attention to when understanding this word?”\\\n",
    "\n",
    "Example:\n",
    "Take the sentence:\n",
    "\n",
    "“The cat sat on the mat because it was warm.”\n",
    "\n",
    "To understand what “it” refers to, self-attention helps the model focus on “cat” or “mat” rather than every word equally. The model figures this out on its own during training.\n",
    "\n",
    "We know that each input word is converted into the embedding right? So then each embedding is project into the three different matrices known as Q, K and V.\n",
    "\n",
    "Q : Query (indicates what each \"token\" is looking for in another token)\n",
    "\n",
    "V : Value (Actual content to be aggregated or weighted)\n",
    "\n",
    "K : Key (Represents the content of each token that other token might find relevant )\n",
    "\n",
    "using seprate linear transformations with learned weights.\n",
    "\n",
    "🧠 Analogy: Job Search Example\n",
    "Imagine you're trying to hire someone:\n",
    "\n",
    "    - Your Query (Q) is the job requirement.\n",
    "\n",
    "    - Each candidate has a Key (K) = their resume.\n",
    "\n",
    "    - The actual Value (V) is what you’d get if you hired them.\n",
    "\n",
    "You compare your Query to all the Keys (resumes) to get scores, then use those scores to weigh the Values (candidates’ actual skills).\n",
    "\n",
    "Values are based on the attention-scores, which are computed by doing the dot-product of the Key and Query matrices\n",
    "So, Attention scores = Q-K similarity(dot - product) from where we get the attention scores(n*n)\n",
    "\n",
    "From the attention scores we apply the Softmax to get the attention weights.\n",
    "\n",
    "so, below is the clear image to show\n",
    "\n",
    "\n",
    "Example : \n",
    "\"orange is my favorite fruit,\" the tokens \"favorite\" and \"fruit\" receive the highest attention when processing \"orange,\" as they directly influence its context and meaning. The model interprets \"orange\" as a favored fruit rather than a color or other meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4ef5d7",
   "metadata": {
    "papermill": {
     "duration": 0.007548,
     "end_time": "2025-06-27T13:22:57.490692",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.483144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### ⚙️ Step-by-step:\n",
    "\n",
    "#### 1. Compute Dot Products:  $Q \\cdot K^T$\n",
    "\n",
    "This gives a score of how much attention word A should pay to word B.\n",
    "\n",
    "#### 2. Scale and Apply Softmax:\n",
    "\n",
    "$$\n",
    "\\text{Attention\\_weights} = \\text{softmax} \\left( \\frac{QK^T}{\\sqrt{d_k}} \\right)\n",
    "$$\n",
    "\n",
    "This normalizes the scores into probabilities.\n",
    "\n",
    "#### 3. Multiply with V:\n",
    "\n",
    "$$\n",
    "\\text{Output} = \\text{Attention\\_weights} \\cdot V\n",
    "$$\n",
    "\n",
    "Each word’s final output is a **weighted sum of all the Value vectors**, based on attention.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd65964",
   "metadata": {
    "papermill": {
     "duration": 0.011301,
     "end_time": "2025-06-27T13:22:57.511369",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.500068",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Multi Attention head\n",
    "\n",
    "Multi-Head Attention is an advanced form of self-attention used in Transformers. Instead of calculating just one set of attention outputs (with one Q/K/V), it creates multiple \"attention heads\" — each learning different relationships or features in the input.\n",
    "\n",
    "⚙️ Why do we need Multi-Head Attention?\n",
    "\n",
    "A single self-attention layer may focus too narrowly. With multi-head attention:\n",
    "\n",
    "- Each head looks at the sequence from a different perspective.\n",
    "\n",
    "- Some heads may learn syntax (e.g., subject-verb links), others learn semantics (e.g., coreference, word meaning).\n",
    "\n",
    "- This makes the model much more expressive.\n",
    "\n",
    "The resulting embeddings capture token meaning, positional encoding, and contextual relationships.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8c180ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:57.531990Z",
     "iopub.status.busy": "2025-06-27T13:22:57.531714Z",
     "iopub.status.idle": "2025-06-27T13:22:57.540824Z",
     "shell.execute_reply": "2025-06-27T13:22:57.540088Z"
    },
    "papermill": {
     "duration": 0.018755,
     "end_time": "2025-06-27T13:22:57.542100",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.523345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-head self-attention mechanism as described in the \"Attention is All You Need\" paper.\n",
    "\n",
    "    Args:\n",
    "        d_model (int): Total dimensionality of the model.\n",
    "        num_heads (int): Number of parallel attention heads.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.head_dim = d_model // num_heads  # Dimension per head\n",
    "\n",
    "        # Linear transformations for query, key, and value (no bias for attention projection)\n",
    "        self.query_linear = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.key_linear = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.value_linear = nn.Linear(d_model, d_model, bias=False)\n",
    "\n",
    "        # Final linear layer after concatenating all heads\n",
    "        self.output_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"\n",
    "        Split the embedding into multiple heads.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): shape (batch_size, seq_len, d_model)\n",
    "\n",
    "        Returns:\n",
    "            Tensor: shape (batch_size, num_heads, seq_len, head_dim)\n",
    "        \"\"\"\n",
    "        seq_length = x.size(1)\n",
    "        x = x.reshape(batch_size, seq_length, self.num_heads, self.head_dim)\n",
    "        return x.permute(0, 2, 1, 3)  # move num_heads before seq_len\n",
    "\n",
    "    def compute_attention(self, query, key, value, mask=None):\n",
    "        \"\"\"\n",
    "        Compute scaled dot-product attention.\n",
    "\n",
    "        Returns:\n",
    "            context vector after attention, shape: (batch_size, num_heads, seq_len, head_dim)\n",
    "        \"\"\"\n",
    "        # Shape: (batch_size, num_heads, seq_len, seq_len)\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / (self.head_dim ** 0.5)\n",
    "\n",
    "        # Apply mask (if provided): mask shape should match scores\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        attention_weights = F.softmax(scores, dim=-1)  # softmax along last dimension\n",
    "        return torch.matmul(attention_weights, value)  # context\n",
    "\n",
    "    def combine_heads(self, x, batch_size):\n",
    "        \"\"\"\n",
    "        Combine the heads back to a single tensor.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): shape (batch_size, num_heads, seq_len, head_dim)\n",
    "\n",
    "        Returns:\n",
    "            Tensor: shape (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        x = x.permute(0, 2, 1, 3).contiguous()  # (batch_size, seq_len, num_heads, head_dim)\n",
    "        return x.view(batch_size, -1, self.d_model)  # combine last two dims\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        # Apply linear transformations\n",
    "        query = self.query_linear(query)\n",
    "        key = self.key_linear(key)\n",
    "        value = self.value_linear(value)\n",
    "\n",
    "        # Split into heads\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # Apply attention on all heads\n",
    "        attn_output = self.compute_attention(query, key, value, mask)\n",
    "\n",
    "        # Combine heads and pass through final linear layer\n",
    "        output = self.combine_heads(attn_output, batch_size)\n",
    "\n",
    "        return self.output_linear(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b857a6e0",
   "metadata": {
    "papermill": {
     "duration": 0.006802,
     "end_time": "2025-06-27T13:22:57.556023",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.549221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## FeedForward SubLayer\n",
    "\n",
    "After the Multi-Head Attention layer in a Transformer block, there's a FeedForward Neural Network (FFN) layer, also known as the FeedForward SubLayer. It adds non-linearity and transformation to each token independently.\n",
    "\n",
    "📌 Why It’s Used\n",
    "\n",
    "While attention layers let tokens communicate, the FFN lets each token transform itself — enriching its internal representation after it has “heard” from others.\n",
    "\n",
    "Our FeedForwardSublayer class contains two fully connected linear layers separated by a ReLU activation. \n",
    "\n",
    "Notice we use a dimension d_ff between linear layers, typically different from the embedding dimension used throughout the model to further facilitate capturing complex patterns. The forward method applies the forward pass to the attention mechanism outputs, passing them through the layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19f7c226",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:57.571214Z",
     "iopub.status.busy": "2025-06-27T13:22:57.570501Z",
     "iopub.status.idle": "2025-06-27T13:22:57.577222Z",
     "shell.execute_reply": "2025-06-27T13:22:57.576502Z"
    },
    "papermill": {
     "duration": 0.015696,
     "end_time": "2025-06-27T13:22:57.578551",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.562855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class FeedForwardSubLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Position-wise Feed-Forward Network used in Transformer blocks.\n",
    "\n",
    "    Args:\n",
    "        d_model (int): Input and output dimensionality (same as the embedding size).\n",
    "        d_ff (int): Hidden dimensionality (usually larger, e.g., 2048 in original paper).\n",
    "\n",
    "    Architecture:\n",
    "        FFN(x) = max(0, xW1 + b1)W2 + b2\n",
    "               = fc2(ReLU(fc1(x)))\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)   # First linear transformation (expands dimension)\n",
    "        self.relu = nn.ReLU()                 # Activation function\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)   # Second linear transformation (projects back to d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))  # Apply FFN to each position independently\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9142a2ba",
   "metadata": {
    "papermill": {
     "duration": 0.007211,
     "end_time": "2025-06-27T13:22:57.598000",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.590789",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Encoder Layer\n",
    "A Transformer Encoder Layer is a single block in the stack of encoder blocks used in models like BERT, GPT (decoder-only variant), and the original Transformer. Each layer processes a sequence of tokens to build richer, context-aware representations.\n",
    "\n",
    "Encoder-only transformers simplify this architecture to place greater emphasis on understanding and representing the input data, such as text classification. \n",
    "\n",
    "They have two main components: \n",
    "- Each encoder layer incorporates a multi-head self-attention mechanism to capture relationships between tokens in the sequence\n",
    "\n",
    "- followed by feed-forward sublayers to map this knowledge into abstract, nonlinear representations. Both elements are usually combined with other techniques like layer normalizations and dropouts to improve training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f9418f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:57.613812Z",
     "iopub.status.busy": "2025-06-27T13:22:57.613158Z",
     "iopub.status.idle": "2025-06-27T13:22:57.621012Z",
     "shell.execute_reply": "2025-06-27T13:22:57.620310Z"
    },
    "papermill": {
     "duration": 0.01704,
     "end_time": "2025-06-27T13:22:57.622158",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.605118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    A single Transformer encoder block.\n",
    "\n",
    "    Consists of:\n",
    "    1. Multi-head self-attention layer with residual connection + LayerNorm\n",
    "    2. Position-wise feed-forward network with residual connection + LayerNorm\n",
    "\n",
    "    Args:\n",
    "        d_model (int): Input/output embedding dimension.\n",
    "        num_heads (int): Number of attention heads.\n",
    "        d_ff (int): Hidden layer size in the feed-forward network.\n",
    "        dropout (float): Dropout rate applied after attention and FFN.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        # Multi-head self-attention\n",
    "        self.attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        # Position-wise feed-forward network\n",
    "        self.ff_sublayer = FeedForwardSubLayer(d_model, d_ff)\n",
    "\n",
    "        # Layer normalizations for residual connections\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, src_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (batch_size, seq_len, d_model)\n",
    "            src_mask: Optional mask for self-attention (batch_size, seq_len, seq_len)\n",
    "\n",
    "        Returns:\n",
    "            Tensor of shape (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "\n",
    "        # === Sublayer 1: Multi-Head Self-Attention ===\n",
    "        attn_output = self.attn(x, x, x, src_mask)  # Q = K = V = x\n",
    "        x = self.norm1(x + self.dropout(attn_output))  # Add & Norm\n",
    "\n",
    "        # === Sublayer 2: Feed-Forward ===\n",
    "        ff_output = self.ff_sublayer(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))  # Add & Norm\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6470c5d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:57.637991Z",
     "iopub.status.busy": "2025-06-27T13:22:57.637265Z",
     "iopub.status.idle": "2025-06-27T13:22:57.645080Z",
     "shell.execute_reply": "2025-06-27T13:22:57.644381Z"
    },
    "papermill": {
     "duration": 0.016906,
     "end_time": "2025-06-27T13:22:57.646255",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.629349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Full Transformer Encoder stack composed of:\n",
    "    - Input token embeddings\n",
    "    - Positional encodings\n",
    "    - N stacked encoder layers\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int): Size of the input vocabulary.\n",
    "        d_model (int): Embedding dimension.\n",
    "        num_layers (int): Number of encoder layers to stack.\n",
    "        num_heads (int): Number of attention heads in each layer.\n",
    "        d_ff (int): Hidden layer size in feed-forward network.\n",
    "        dropout (float): Dropout rate for regularization.\n",
    "        max_seq_length (int): Maximum input sequence length.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length):\n",
    "        super().__init__()\n",
    "\n",
    "        # Token embedding + positional encoding\n",
    "        self.embedding = InputEmbeddings(vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        # Stack of N encoder layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, num_heads, d_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, src_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): Input token IDs, shape (batch_size, seq_len)\n",
    "            src_mask (Tensor or None): Attention mask, shape (batch_size, seq_len, seq_len)\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Encoded representation, shape (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        # Embed token IDs and add positional information\n",
    "        x = self.embedding(x)                          # (batch_size, seq_len, d_model)\n",
    "        x = self.positional_encoding(x)                # (batch_size, seq_len, d_model)\n",
    "\n",
    "        # Pass through each encoder layer\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src_mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd57a21c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:57.661693Z",
     "iopub.status.busy": "2025-06-27T13:22:57.661048Z",
     "iopub.status.idle": "2025-06-27T13:22:57.668823Z",
     "shell.execute_reply": "2025-06-27T13:22:57.668083Z"
    },
    "papermill": {
     "duration": 0.016825,
     "end_time": "2025-06-27T13:22:57.670176",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.653351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        # Define cross-attention and a third layer normalization\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ff_sublayer = FeedForwardSubLayer(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, y, tgt_mask, cross_mask):\n",
    "        self_attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(self_attn_output))\n",
    "        # Complete the forward pass\n",
    "        cross_attn_output = self.cross_attn(x, y, y, cross_mask)\n",
    "        x = self.norm2(x + self.dropout(cross_attn_output))\n",
    "        ff_output = self.ff_sublayer(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae4178b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:57.701645Z",
     "iopub.status.busy": "2025-06-27T13:22:57.701247Z",
     "iopub.status.idle": "2025-06-27T13:22:57.743103Z",
     "shell.execute_reply": "2025-06-27T13:22:57.742289Z"
    },
    "papermill": {
     "duration": 0.061263,
     "end_time": "2025-06-27T13:22:57.744665",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.683402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "seq_length = 32\n",
    "\n",
    "# Create an upper triangular matrix filled with -inf (mask), 0 elsewhere\n",
    "tgt_mask = torch.triu(torch.ones(seq_length, seq_length), diagonal=1).bool()\n",
    "\n",
    "# Invert the mask if your attention mask expects 1s for valid tokens\n",
    "# This version sets True for allowed tokens (lower triangle including diagonal)\n",
    "causal_mask = ~tgt_mask  # optional depending on your attention implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f47ecd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:57.764245Z",
     "iopub.status.busy": "2025-06-27T13:22:57.763943Z",
     "iopub.status.idle": "2025-06-27T13:22:57.769515Z",
     "shell.execute_reply": "2025-06-27T13:22:57.769046Z"
    },
    "papermill": {
     "duration": 0.01612,
     "end_time": "2025-06-27T13:22:57.770663",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.754543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.embedding = InputEmbeddings(vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "        # Define the list of decoder layers and linear layer\n",
    "        self.layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        # Define a linear layer to project hidden states to likelihoods\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "  \n",
    "    def forward(self, x, encoder_output, tgt_mask=None, cross_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Target input token IDs (batch_size, tgt_seq_len)\n",
    "            encoder_output: Output from encoder (batch_size, src_seq_len, d_model)\n",
    "            tgt_mask: Mask for decoder self-attention (batch_size, tgt_seq_len, tgt_seq_len)\n",
    "            cross_mask: Mask for cross-attention (batch_size, tgt_seq_len, src_seq_len)\n",
    "        Returns:\n",
    "            Logits over vocabulary (batch_size, tgt_seq_len, vocab_size)\n",
    "        \"\"\"\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x, encoder_output, tgt_mask, cross_mask)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a606d0c5",
   "metadata": {
    "papermill": {
     "duration": 0.006753,
     "end_time": "2025-06-27T13:22:57.785545",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.778792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Encoder-Decoder Attention\n",
    "\n",
    "The encoder-decoder attention mechanism serves as the bridge that connects the\n",
    "encoder and the decoder, facilitating the transfer of contextual information from\n",
    "the source sequence to the target sequence.\n",
    "\n",
    "#### Cross Attention Mechanism\n",
    "It occurs in each decoder layer after the masked attention, taking two inputs: \n",
    "- The Queries (Q) are derived from the decoder’s current state.\n",
    "- The Keys (K) and Values (V) come from the encoder’s output.\n",
    "\n",
    "This setup allows the decoder to attend to relevant parts of the input sequence\n",
    "while generating each token in the output. As a result, the model can learn\n",
    "complex dependencies between source and target tokens.\n",
    "\n",
    "✅ Source Sentence (English):\n",
    "\"I really like to travel.\"\n",
    "\n",
    "🎯 Target Translation (Spanish in progress):\n",
    "\"Me gusta Mucho  \"\n",
    "Now the decoder is trying to predict the next word.\n",
    "\n",
    "#### 1️⃣ Encoder Processes the Source\n",
    "The encoder reads:\n",
    "\"I really like to travel\"\n",
    "and stores contextual information (hidden states) for each word:\n",
    "\n",
    "\"I\"\n",
    "\n",
    "\"really\"\n",
    "\n",
    "\"like\"\n",
    "\n",
    "\"to\"\n",
    "\n",
    "\"travel\"\n",
    "\n",
    "This information becomes the Key (K) and Value (V) vectors.\n",
    "\n",
    "#### 2️⃣ Decoder Has Generated So Far:\n",
    "\"Me gusta mucho \"\n",
    "(which means “I like very much…”)\n",
    "\n",
    "Now the decoder must predict the next word, ideally:\n",
    "➡️ \"viajar\" (Spanish for “to travel”)\n",
    "\n",
    "#### 3️⃣ How Encoder-Decoder Attention Helps:\n",
    "The decoder forms a Query (Q) using its current hidden state — influenced by:\n",
    "\"Me gusta mucho\"\n",
    "\n",
    "It performs attention over the encoder’s K & V vectors — specifically looking at which source word is most relevant right now.\n",
    "\n",
    "It attends most strongly to:\n",
    "\n",
    "the English word: \"travel\"\n",
    "\n",
    "Based on this, it predicts:\n",
    "✅ \"viajar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b021705",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:57.800904Z",
     "iopub.status.busy": "2025-06-27T13:22:57.800597Z",
     "iopub.status.idle": "2025-06-27T13:22:57.805717Z",
     "shell.execute_reply": "2025-06-27T13:22:57.805033Z"
    },
    "papermill": {
     "duration": 0.014351,
     "end_time": "2025-06-27T13:22:57.806870",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.792519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder = TransformerEncoder(vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length)\n",
    "        self.decoder = TransformerDecoder(vocab_size, d_model, num_layers, num_heads, d_ff, dropout, max_seq_length)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask=None, tgt_mask=None, cross_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Source input IDs (batch_size, src_seq_len)\n",
    "            tgt: Target input IDs (batch_size, tgt_seq_len)\n",
    "        Returns:\n",
    "            Decoder output logits\n",
    "        \"\"\"\n",
    "        encoder_output = self.encoder(src, src_mask)\n",
    "        decoder_output = self.decoder(tgt, encoder_output, tgt_mask, cross_mask)\n",
    "        return decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45a13290",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:57.821785Z",
     "iopub.status.busy": "2025-06-27T13:22:57.821410Z",
     "iopub.status.idle": "2025-06-27T13:22:57.842488Z",
     "shell.execute_reply": "2025-06-27T13:22:57.841767Z"
    },
    "papermill": {
     "duration": 0.029975,
     "end_time": "2025-06-27T13:22:57.843789",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.813814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "batch_size = 16\n",
    "\n",
    "dataset = SummarizationDataset(\n",
    "    headline=df['headline'].tolist(),\n",
    "    short_description=df['short_description'].tolist(),\n",
    "    word2idx=word2idx,\n",
    "    max_len=64  # or your preferred length\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db37d8bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:57.866878Z",
     "iopub.status.busy": "2025-06-27T13:22:57.866366Z",
     "iopub.status.idle": "2025-06-27T13:22:57.905629Z",
     "shell.execute_reply": "2025-06-27T13:22:57.904853Z"
    },
    "papermill": {
     "duration": 0.053976,
     "end_time": "2025-06-27T13:22:57.906906",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.852930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch input shape: torch.Size([16, 64])\n",
      "Test batch input shape: torch.Size([16, 64])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    input_ids = batch['input_ids']\n",
    "    target_ids = batch['target_ids']\n",
    "    print(\"Train batch input shape:\", input_ids.shape)\n",
    "    break\n",
    "\n",
    "for batch in test_loader:\n",
    "    input_ids = batch['input_ids']\n",
    "    target_ids = batch['target_ids']\n",
    "    print(\"Test batch input shape:\", input_ids.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d83cc842",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:22:57.922845Z",
     "iopub.status.busy": "2025-06-27T13:22:57.922099Z",
     "iopub.status.idle": "2025-06-27T13:23:03.868762Z",
     "shell.execute_reply": "2025-06-27T13:23:03.867767Z"
    },
    "papermill": {
     "duration": 5.956027,
     "end_time": "2025-06-27T13:23:03.870294",
     "exception": false,
     "start_time": "2025-06-27T13:22:57.914267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\r\n",
      "Collecting rouge-score\r\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\r\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.0)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\r\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.26.4)\r\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge-score) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge-score) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge-score) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge-score) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge-score) (2024.2.0)\r\n",
      "Building wheels for collected packages: rouge-score\r\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=04215e1ccc54360b7e23c5c16a7c7670b5f970c63e8286bf86a996537232affe\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\r\n",
      "Successfully built rouge-score\r\n",
      "Installing collected packages: rouge-score\r\n",
      "Successfully installed rouge-score-0.1.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "894722ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:23:03.887861Z",
     "iopub.status.busy": "2025-06-27T13:23:03.887204Z",
     "iopub.status.idle": "2025-06-27T13:23:03.942095Z",
     "shell.execute_reply": "2025-06-27T13:23:03.941393Z"
    },
    "papermill": {
     "duration": 0.065023,
     "end_time": "2025-06-27T13:23:03.943331",
     "exception": false,
     "start_time": "2025-06-27T13:23:03.878308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24e942d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:23:03.959525Z",
     "iopub.status.busy": "2025-06-27T13:23:03.958941Z",
     "iopub.status.idle": "2025-06-27T13:23:03.964915Z",
     "shell.execute_reply": "2025-06-27T13:23:03.964352Z"
    },
    "papermill": {
     "duration": 0.015032,
     "end_time": "2025-06-27T13:23:03.966001",
     "exception": false,
     "start_time": "2025-06-27T13:23:03.950969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_tokens(token_ids, idx2word, eos_token='<PAD>'):\n",
    "    words = []\n",
    "    for idx in token_ids:\n",
    "        word = idx2word.get(idx.item(), '<UNK>')\n",
    "        if word == eos_token:\n",
    "            break\n",
    "        words.append(word)\n",
    "    return ' '.join(words)\n",
    "\n",
    "def greedy_decode(model, src, word2idx, max_len=64):\n",
    "    model.eval()\n",
    "    src = src.to(device)\n",
    "    encoder_output = model.encoder(src)\n",
    "\n",
    "    ys = torch.ones((src.size(0), 1), dtype=torch.long).fill_(word2idx['<PAD>']).to(device)\n",
    "\n",
    "    for i in range(max_len - 1):\n",
    "        tgt_mask = torch.triu(torch.ones(ys.size(1), ys.size(1)), diagonal=1).bool().to(device)\n",
    "        tgt_mask = ~tgt_mask\n",
    "        out = model.decoder(ys, encoder_output, tgt_mask, cross_mask=None)\n",
    "        next_token = out[:, -1, :].argmax(dim=-1).unsqueeze(1)\n",
    "        ys = torch.cat([ys, next_token], dim=1)\n",
    "\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c5fc2f",
   "metadata": {
    "papermill": {
     "duration": 0.007055,
     "end_time": "2025-06-27T13:23:03.980806",
     "exception": false,
     "start_time": "2025-06-27T13:23:03.973751",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c2b7c5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:23:03.996573Z",
     "iopub.status.busy": "2025-06-27T13:23:03.996206Z",
     "iopub.status.idle": "2025-06-27T13:23:04.003985Z",
     "shell.execute_reply": "2025-06-27T13:23:04.003384Z"
    },
    "papermill": {
     "duration": 0.017064,
     "end_time": "2025-06-27T13:23:04.005068",
     "exception": false,
     "start_time": "2025-06-27T13:23:03.988004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, idx2word, word2idx, criterion, max_len=64):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    total_tokens = 0\n",
    "    bleu_scores = []\n",
    "    rouge_l_scores = []\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    smooth_fn = SmoothingFunction().method1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
    "            src = batch['input_ids'].to(device)\n",
    "            tgt = batch['target_ids'].to(device)\n",
    "\n",
    "            decoder_input = tgt[:, :-1]\n",
    "            target_output = tgt[:, 1:]\n",
    "\n",
    "            seq_len = decoder_input.size(1)\n",
    "            tgt_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool().to(device)\n",
    "            tgt_mask = ~tgt_mask\n",
    "\n",
    "            outputs = model(src, decoder_input, src_mask=None, tgt_mask=tgt_mask, cross_mask=None)\n",
    "\n",
    "            loss = criterion(outputs.view(-1, outputs.size(-1)), target_output.reshape(-1))\n",
    "\n",
    "            running_loss += loss.item() * target_output.numel()\n",
    "            total_tokens += target_output.numel()\n",
    "\n",
    "            # Greedy decode for BLEU/ROUGE (optional: can be slow, so sample a few batches)\n",
    "            generated_ids = greedy_decode(model, src, word2idx, max_len)\n",
    "\n",
    "            for pred_seq, true_seq in zip(generated_ids, tgt):\n",
    "                pred_text = decode_tokens(pred_seq, idx2word)\n",
    "                true_text = decode_tokens(true_seq[1:], idx2word)  # skip <PAD>/<BOS>\n",
    "\n",
    "                reference = [nltk.word_tokenize(true_text)]\n",
    "                candidate = nltk.word_tokenize(pred_text)\n",
    "\n",
    "                bleu = sentence_bleu(reference, candidate, smoothing_function=smooth_fn)\n",
    "                bleu_scores.append(bleu)\n",
    "\n",
    "                rouge = scorer.score(true_text, pred_text)['rougeL'].fmeasure\n",
    "                rouge_l_scores.append(rouge)\n",
    "\n",
    "    avg_loss = running_loss / total_tokens\n",
    "    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "    avg_rouge = sum(rouge_l_scores) / len(rouge_l_scores)\n",
    "\n",
    "    return avg_loss, avg_bleu, avg_rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca1dac2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:23:04.020953Z",
     "iopub.status.busy": "2025-06-27T13:23:04.020385Z",
     "iopub.status.idle": "2025-06-27T13:23:09.467269Z",
     "shell.execute_reply": "2025-06-27T13:23:09.466485Z"
    },
    "papermill": {
     "duration": 5.456212,
     "end_time": "2025-06-27T13:23:09.468727",
     "exception": false,
     "start_time": "2025-06-27T13:23:04.012515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Transformer(\n",
    "    vocab_size=len(word2idx),\n",
    "    d_model=512,\n",
    "    num_heads=8,\n",
    "    num_layers=2,\n",
    "    d_ff=2048,\n",
    "    max_seq_length=64,  # match with dataset\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "pad_idx = word2idx['<PAD>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daa9529",
   "metadata": {
    "papermill": {
     "duration": 0.007487,
     "end_time": "2025-06-27T13:23:09.484319",
     "exception": false,
     "start_time": "2025-06-27T13:23:09.476832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a18c06fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T13:23:09.500201Z",
     "iopub.status.busy": "2025-06-27T13:23:09.499792Z",
     "iopub.status.idle": "2025-06-27T14:06:00.323126Z",
     "shell.execute_reply": "2025-06-27T14:06:00.322491Z"
    },
    "papermill": {
     "duration": 2570.83282,
     "end_time": "2025-06-27T14:06:00.324511",
     "exception": false,
     "start_time": "2025-06-27T13:23:09.491691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 — Train Loss: 7.1666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 — Val Loss: 6.6670, BLEU: 0.0000, ROUGE-L: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 — Train Loss: 6.1833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 — Val Loss: 6.3771, BLEU: 0.0000, ROUGE-L: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 — Train Loss: 5.6400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 — Val Loss: 6.2364, BLEU: 0.0000, ROUGE-L: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 — Train Loss: 5.1850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 — Val Loss: 6.1972, BLEU: 0.0000, ROUGE-L: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 — Train Loss: 4.7525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 — Val Loss: 6.2321, BLEU: 0.0000, ROUGE-L: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Training + evaluation loop\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_tokens = 0\n",
    "\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "\n",
    "    for batch in loop:\n",
    "        input_ids = batch['input_ids'].to(device)    # (B, S)\n",
    "        target_ids = batch['target_ids'].to(device)  # (B, S)\n",
    "\n",
    "        decoder_input = target_ids[:, :-1]\n",
    "        target_output = target_ids[:, 1:]\n",
    "\n",
    "        seq_len = decoder_input.size(1)\n",
    "        tgt_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool().to(device)\n",
    "        tgt_mask = ~tgt_mask\n",
    "\n",
    "        outputs = model(input_ids, decoder_input, src_mask=None, tgt_mask=tgt_mask, cross_mask=None)\n",
    "\n",
    "        loss = criterion(outputs.view(-1, outputs.size(-1)), target_output.reshape(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * target_output.numel()\n",
    "        total_tokens += target_output.numel()\n",
    "\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    epoch_loss = running_loss / total_tokens\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} — Train Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Evaluate on validation/test set\n",
    "    val_loss, val_bleu, val_rouge = evaluate_model(model, test_loader, idx2word, word2idx, criterion, max_len=64)\n",
    "    print(f\"Epoch {epoch+1} — Val Loss: {val_loss:.4f}, BLEU: {val_bleu:.4f}, ROUGE-L: {val_rouge:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23fd959",
   "metadata": {
    "papermill": {
     "duration": 0.936082,
     "end_time": "2025-06-27T14:06:02.208247",
     "exception": false,
     "start_time": "2025-06-27T14:06:01.272165",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "708489a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T14:06:04.144489Z",
     "iopub.status.busy": "2025-06-27T14:06:04.143896Z",
     "iopub.status.idle": "2025-06-27T14:06:04.151000Z",
     "shell.execute_reply": "2025-06-27T14:06:04.150283Z"
    },
    "papermill": {
     "duration": 0.946155,
     "end_time": "2025-06-27T14:06:04.152107",
     "exception": false,
     "start_time": "2025-06-27T14:06:03.205952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, word2idx, idx2word, max_len=64, device='cpu'):\n",
    "    \"\"\"\n",
    "    Generate summary tokens greedily from the encoder output.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    src = src.to(device)\n",
    "\n",
    "    # Encode source sequence\n",
    "    encoder_output = model.encoder(src)\n",
    "\n",
    "    # Start with a meaningful token - try using the most common word or create a BOS token\n",
    "    # For now, let's start with the first non-PAD token from vocabulary\n",
    "    start_token = 2  # Skip <PAD>=0 and <UNK>=1, start with first real word\n",
    "    ys = torch.tensor([[start_token]], dtype=torch.long).to(device)\n",
    "\n",
    "    generated_tokens = []\n",
    "    \n",
    "    for _ in range(max_len - 1):\n",
    "        seq_len = ys.size(1)\n",
    "        tgt_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool().to(device)\n",
    "        tgt_mask = ~tgt_mask\n",
    "\n",
    "        # Decode step\n",
    "        with torch.no_grad():\n",
    "            out = model.decoder(ys, encoder_output, tgt_mask, cross_mask=None)\n",
    "            prob = out[:, -1, :]  # Get last token's predictions\n",
    "            next_word = prob.argmax(dim=-1).unsqueeze(1)\n",
    "\n",
    "        ys = torch.cat([ys, next_word], dim=1)\n",
    "        \n",
    "        token_id = next_word.item()\n",
    "        word = idx2word.get(token_id, '<UNK>')\n",
    "        \n",
    "        # Stop if we hit PAD or if we're repeating PAD\n",
    "        if word == '<PAD>' and len(generated_tokens) > 0:\n",
    "            break\n",
    "            \n",
    "        if word not in ['<PAD>', '<UNK>']:\n",
    "            generated_tokens.append(word)\n",
    "\n",
    "    return ' '.join(generated_tokens) if generated_tokens else \"no output generated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "613aef15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T14:06:06.022537Z",
     "iopub.status.busy": "2025-06-27T14:06:06.021874Z",
     "iopub.status.idle": "2025-06-27T14:06:06.863383Z",
     "shell.execute_reply": "2025-06-27T14:06:06.862785Z"
    },
    "papermill": {
     "duration": 1.783815,
     "end_time": "2025-06-27T14:06:06.864579",
     "exception": false,
     "start_time": "2025-06-27T14:06:05.080764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1\n",
      "Actual Headline:\n",
      "over 4 million americans roll up sleeves for omicrontargeted covid boosters\n",
      "\n",
      "Predicted Headline:\n",
      "us military ban on syria strike group in yemen war <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "--------------------------------------------------------------------------------\n",
      "Example 2\n",
      "Actual Headline:\n",
      "american airlines flyer charged banned for life after punching flight attendant on video\n",
      "\n",
      "Predicted Headline:\n",
      "trump administration seeks to fire robert mueller probe <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "--------------------------------------------------------------------------------\n",
      "Example 3\n",
      "Actual Headline:\n",
      "23 of the funniest tweets about cats and dogs this week sept 1723\n",
      "\n",
      "Predicted Headline:\n",
      "the funniest tweets from parents this week sept 1723 <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "--------------------------------------------------------------------------------\n",
      "Example 4\n",
      "Actual Headline:\n",
      "the funniest tweets from parents this week sept 1723\n",
      "\n",
      "Predicted Headline:\n",
      "the funniest tweets from parents this week sept 1723 <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "--------------------------------------------------------------------------------\n",
      "Example 5\n",
      "Actual Headline:\n",
      "woman who called cops on black birdwatcher loses lawsuit against exemployer\n",
      "\n",
      "Predicted Headline:\n",
      "former cia director defends roy moore accuser for alleged sexual assault allegations <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "--------------------------------------------------------------------------------\n",
      "Example 6\n",
      "Actual Headline:\n",
      "cleaner was dead in belk bathroom for 4 days before body found police\n",
      "\n",
      "Predicted Headline:\n",
      "woman arrested after alleged child sex abuse in prison <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "--------------------------------------------------------------------------------\n",
      "Example 7\n",
      "Actual Headline:\n",
      "reporter gets adorable surprise from her boyfriend while live on tv\n",
      "\n",
      "Predicted Headline:\n",
      "hillary clinton is not a very good idea <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "--------------------------------------------------------------------------------\n",
      "Example 8\n",
      "Actual Headline:\n",
      "puerto ricans desperate for water after hurricane fionas rampage\n",
      "\n",
      "Predicted Headline:\n",
      "hurricane harvey is a hurricane irma in the world <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "--------------------------------------------------------------------------------\n",
      "Example 9\n",
      "Actual Headline:\n",
      "how a new documentary captures the complexity of being a child of immigrants\n",
      "\n",
      "Predicted Headline:\n",
      "the new york times is a new york city <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "--------------------------------------------------------------------------------\n",
      "Example 10\n",
      "Actual Headline:\n",
      "biden at un to call russian war an affront to bodys charter\n",
      "\n",
      "Predicted Headline:\n",
      "trumps russia is a war on the us <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS>\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    article_text = df['short_description'][i]\n",
    "    reference_headline = df['headline'][i]  # actual cleaned summary text\n",
    "\n",
    "    input_ids = torch.tensor(encode_text(article_text, word2idx, max_len=64)).unsqueeze(0)  # (1, max_len)\n",
    "    predicted_headline = greedy_decode(model, input_ids, word2idx, idx2word, max_len=32, device=device)\n",
    "\n",
    "    print(f\"Example {i+1}\")\n",
    "    print(\"Actual Headline:\")\n",
    "    print(reference_headline)\n",
    "    print(\"\\nPredicted Headline:\")\n",
    "    print(predicted_headline)\n",
    "    print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba9e51a",
   "metadata": {
    "papermill": {
     "duration": 0.865658,
     "end_time": "2025-06-27T14:06:08.672869",
     "exception": false,
     "start_time": "2025-06-27T14:06:07.807211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1654566,
     "sourceId": 2734496,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 32526,
     "sourceId": 4243451,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2617.101982,
   "end_time": "2025-06-27T14:06:13.129031",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-27T13:22:36.027049",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
